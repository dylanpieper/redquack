[{"path":"https://dylanpieper.github.io/redquack/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 arrowcap authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://dylanpieper.github.io/redquack/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dylan Pieper. Author, maintainer.","code":""},{"path":"https://dylanpieper.github.io/redquack/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Pieper D (2025). redquack: REDCap Data Export DuckDB. R package version 0.1.0.","code":"@Manual{,   title = {redquack: REDCap Data Export to DuckDB},   author = {Dylan Pieper},   year = {2025},   note = {R package version 0.1.0}, }"},{"path":"https://dylanpieper.github.io/redquack/index.html","id":"redquack-","dir":"","previous_headings":"","what":"REDCap Data Export to DuckDB","title":"REDCap Data Export to DuckDB","text":"redquack provides single function redcap_to_duckdb() exporting REDCap data local DuckDB database batches, limits memory usage big datasets.","code":""},{"path":"https://dylanpieper.github.io/redquack/index.html","id":"features","dir":"","previous_headings":"","what":"Features","title":"REDCap Data Export to DuckDB","text":"Batch processing large REDCap projects DuckDB Optimize column types gracefully handle conflicts across batches Log process separate database table Track progress console messages sound notifications (quacks success)","code":""},{"path":"https://dylanpieper.github.io/redquack/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"REDCap Data Export to DuckDB","text":"","code":"install.packages(\"redquack\")"},{"path":"https://dylanpieper.github.io/redquack/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"REDCap Data Export to DuckDB","text":"Export REDCap project DuckDB database:","code":"library(redquack)  con <- redcap_to_duckdb(   redcap_uri = \"https://redcap.example.org/api/\",   token = \"YOUR_API_TOKEN\" )"},{"path":"https://dylanpieper.github.io/redquack/index.html","id":"function-parameters","dir":"","previous_headings":"Usage","what":"Function parameters","title":"REDCap Data Export to DuckDB","text":"redcap_to_duckdb() function includes several parameters customize extraction: projects many fields, may want decrease chunk_size:","code":"con <- redcap_to_duckdb(   redcap_uri = \"https://redcap.example.org/api/\",   token = \"YOUR_API_TOKEN\",   chunk_size = 500 )"},{"path":"https://dylanpieper.github.io/redquack/index.html","id":"working-with-the-exported-data","dir":"","previous_headings":"Usage","what":"Working with the exported data","title":"REDCap Data Export to DuckDB","text":"Query data dplyr: Export data Parquet sharing archiving: create Parquet directly DuckDB avoid loading data memory: Remember close connection finished:","code":"library(dplyr)  demographics <- tbl(con, \"data\") |>   filter(form_complete == 2) |>   select(id, age, race, gender) |>   collect() library(arrow)  tbl(con, \"data\") |>   collect() |>   write_parquet(\"redcap.parquet\") DBI::dbExecute(con, \"COPY (SELECT * FROM data) TO 'redcap.parquet' (FORMAT PARQUET)\") DBI::dbDisconnect(con, shutdown = TRUE)"},{"path":"https://dylanpieper.github.io/redquack/index.html","id":"database-structure","dir":"","previous_headings":"","what":"Database structure","title":"REDCap Data Export to DuckDB","text":"DuckDB database created redcap_to_duckdb() contains two tables: data: Contains exported REDCap records log: Contains timestamped logs extraction process Query log table check extraction details:","code":"DBI::dbGetQuery(con, \"SELECT * FROM log ORDER BY timestamp\")"},{"path":"https://dylanpieper.github.io/redquack/reference/redcap_to_duckdb.html","id":null,"dir":"Reference","previous_headings":"","what":"Export REDCap data to DuckDB — redcap_to_duckdb","title":"Export REDCap data to DuckDB — redcap_to_duckdb","text":"Read REDCap project data save DuckDB database file. Process data batches handle large projects minimizing memory usage.","code":""},{"path":"https://dylanpieper.github.io/redquack/reference/redcap_to_duckdb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export REDCap data to DuckDB — redcap_to_duckdb","text":"","code":"redcap_to_duckdb(   redcap_uri,   token,   output_file = \"redcap.duckdb\",   chunk_size = 2000,   chunk_delay = 0.5,   id_field = \"id\",   optimize_types = TRUE,   return_duckdb = TRUE,   suppress_warnings = TRUE,   beep = TRUE,   ... )"},{"path":"https://dylanpieper.github.io/redquack/reference/redcap_to_duckdb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export REDCap data to DuckDB — redcap_to_duckdb","text":"redcap_uri Character string specifying URI (uniform resource identifier) REDCap server's API. token Character string containing REDCap API token specific project. token used authentication must export permissions. output_file Character string specifying file path DuckDB database created modified. Default \"redcap.duckdb\" current working directory. chunk_size Integer specifying number record IDs process per batch. Default 2000. Consider decreasing projects many fields. chunk_delay Numeric value specifying delay seconds batch requests. Default 0.5 seconds. Adjust respect REDCap server limits. id_field Character string specifying field name contains record identifiers. Default \"id\". optimize_types Logical indicating whether column types optimized data inserted. Default TRUE, analyzes column content converts VARCHAR appropriate types (INTEGER, DOUBLE, DATE, TIMESTAMP). FALSE, columns remain VARCHAR regardless content. return_duckdb Logical indicating whether return DBI connection object. Default TRUE. FALSE, return NULL invisibly. suppress_warnings Logical indicating whether suppress common REDCap parsing warnings. Default TRUE. beep Logical indicating whether play sound notifications process completes encounters errors. Default TRUE. ... Additional arguments passed REDCapR::redcap_read_oneshot().","code":""},{"path":"https://dylanpieper.github.io/redquack/reference/redcap_to_duckdb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Export REDCap data to DuckDB — redcap_to_duckdb","text":"return_duckdb TRUE, returns DBI connection object DuckDB database. Connection attributes: had_errors: Logical indicating errors occurred extraction error_batches: Vector batch numbers failed processing () return_duckdb FALSE, returns invisibly.","code":""},{"path":"https://dylanpieper.github.io/redquack/reference/redcap_to_duckdb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Export REDCap data to DuckDB — redcap_to_duckdb","text":"function extracts data REDCap project batches, helps manage memory usage dealing large projects. creates two tables DuckDB database: data: Contains extracted REDCap records log: Contains timestamped logs extraction process function fetches record IDs first, processes records batches. error occurs batch processing, function stop processing prevent incomplete data. Memory explicitly managed handle large datasets. data initially stored VARCHAR type consistent handling across batches. optimize_types = TRUE (default), column types automatically converted data inserted, based content analysis: Columns containing integers converted INTEGER Columns containing numeric values converted DOUBLE Columns valid date strings converted DATE Columns valid timestamp strings converted TIMESTAMP columns remain VARCHAR optimize_types = FALSE, columns remain VARCHAR type. can useful : need consistent string-based handling data working complex mixed-type data plan handle type conversions manually subsequent SQL queries Import speed prioritized storage efficiency query optimization","code":""},{"path":"https://dylanpieper.github.io/redquack/reference/redcap_to_duckdb.html","id":"database-connection","dir":"Reference","previous_headings":"","what":"Database Connection","title":"Export REDCap data to DuckDB — redcap_to_duckdb","text":"function returns open connection DuckDB database return_duckdb = TRUE. must explicitly close connection DBI::dbDisconnect() finished.","code":""},{"path":[]},{"path":"https://dylanpieper.github.io/redquack/reference/redcap_to_duckdb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Export REDCap data to DuckDB — redcap_to_duckdb","text":"","code":"if (FALSE) { # \\dontrun{ # Basic usage with API token con <- redcap_to_duckdb(   redcap_uri = \"https://redcap.example.org/api/\",   token = \"YOUR_API_TOKEN\" )  # Alternatively, suppress console messages con <- suppressMessages(redcap_to_duckdb(   redcap_uri = \"https://redcap.example.org/api/\",   token = \"YOUR_API_TOKEN\" ))  # Query the resulting database records <- DBI::dbGetQuery(con, \"SELECT * FROM data LIMIT 10\")  # View extraction logs logs <- DBI::dbGetQuery(con, \"SELECT * FROM log\")  # Remember to close the connection DBI::dbDisconnect(con, shutdown = TRUE) } # }"},{"path":"https://dylanpieper.github.io/redquack/news/index.html","id":"redquack-010","dir":"Changelog","previous_headings":"","what":"redquack 0.1.0","title":"redquack 0.1.0","text":"Initial CRAN submission Single function redcap_to_duckdb() exporting REDCap data DuckDB Batch processing limit memory usage large datasets Automatic column type optimization handle conflicts Process logging separate database table Progress tracking console messages Sound notifications (quacks success)","code":""}]
